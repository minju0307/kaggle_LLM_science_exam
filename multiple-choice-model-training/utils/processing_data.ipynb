{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b87e1e-e8b1-43e0-a04d-70d45c47577b",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "294a578d-a155-47bc-a62e-71c046b75684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2effa25a50c4a9a985e5d110ded138e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db86da78d8948b6aefb055a4744b1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ead1f924ef4b65adb498b0d9134010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7733be59a45e4b78b721ac1e521fce81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric \n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train':[\"../dataset/MMLU_train_set.csv\"], 'test':['../dataset/MMLU_dev_set.csv']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "44c037b3-bf7d-4b9b-8f03-80934e62a5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'A', 'B', 'C', 'D', 'answer'],\n",
      "        num_rows: 99842\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'A', 'B', 'C', 'D', 'answer'],\n",
      "        num_rows: 285\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a8a06bfd-05e9-452d-92ae-a9be24aab2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were\",\n",
       " 'A': 'Adams only.',\n",
       " 'B': 'Brooks only.',\n",
       " 'C': 'Case only.',\n",
       " 'D': 'Adams and Brooks',\n",
       " 'answer': 'B'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d7094cfa-8bd3-407c-a430-bcf92bc0b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a53eb05d-d5e0-42f7-a99a-39a14e81a923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It was something she had dreamed of since she was five. Finally, after years of training and intensive workouts, Deborah Duffey was going to compete in her first high school basketball game. The goals of becoming an outstanding player and playing college ball were never far from Deborah's mind. The game was against Mills High School. With 1 minute and 42 seconds left in the game, Deborah's team led by one point. A player of Mills had possession of the ball,and Deborah ran to guard against her. As Deborah was running to block the player, her knee went out and she fell down on the court in burning pain. Just like that, Deborah's season was over. After suffering the bad injury, Deborah found that, for the first time in her life, she was in a situation beyond her control. Game after game, she could do nothing but sit on the sidelines watching others play the game that she loved so much. Injuries limited Deborah's time on the court as she hurt her knees three more times in the next five years. She had to spend countless hours in a physical clinic to receive treatment. Her frequent visits there gave her a passion and respect for the profession.  And Deborah began to see a new light in her life. Currently as a senior in college, Deborah focuses on getting a degree in physical treatment. After she graduates, Deborah plans to use her knowledge to educate people how to best take care of their bodies and cope with the feelings of hopelessness that she remembers so well. What is the best title for this passage?</td>\n",
       "      <td>A Painful Mistake</td>\n",
       "      <td>A Great Adventure</td>\n",
       "      <td>A Lifelong Punishment</td>\n",
       "      <td>A New Direction in Life</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which best determines the health of a lake used as a source of freshwater?</td>\n",
       "      <td>its depth and width</td>\n",
       "      <td>its temperature and pH</td>\n",
       "      <td>its location and depth</td>\n",
       "      <td>its temperature and depth</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to decades-long research, women who took low to moderate  daily doses of aspirin had a reduced death rate, especially from heart disease. The research, based on data from a major trial that has tracked almost 80,000 women since 1976, found that women who reported using aspirin on a regular basis had a 25 percent lower risk of death from any cause than women who didn't take the drug.   The risk of death from cardiovascular  disease was 38 percent lower for aspirin users, and there was also a 12 percent reduction in cancer deaths that took effect after a decade of aspirin use, the researchers found in their report based on the Nurses' Health Study. However, an accompanying editorial in the journal cautioned that the results were open to debate and far from definitive.       The dissenting   editorial was based on results of an earlier trial by the Women's Health Study, which followed almost 40,000 women for 11 years and found no reduction in overall deaths. Therefore, the new findings \"cannot overcome the accumulated evidence that aspirin is not particularly effective for the primary prevention of death from cardiovascular disease in women.\"       \"This is a complicated issue,\" said Dr. Andrew T. Chan, leading author of the new report. \"We understand that aspirin has potential health benefits, but who would aspirin therapy  be appropriate for?\" There are \"areas of disagreement that need further study\" before that question can be answered, Chan said. But there is information from the two large studies and other trials that can help guide women and their physicians, he said. And anyone who is thinking about daily aspirin \"should really talk with doctors about the benefits and risks.\" Which of the following questions hasn't been solved according to Dr. Chan?</td>\n",
       "      <td>Whether aspirin is beneficial for health?</td>\n",
       "      <td>Which of the two researches is really reliable?</td>\n",
       "      <td>Who will do the further study in this area?</td>\n",
       "      <td>Who are proper for this treatment?</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For years, business people in Western Europe were worried. They knew they could not compete against business from the U.S. The United States is much larger and had many more resources than any Western European countries. Some European people realized that the European nations need to join together to help each other. If they could forget their language differences and the differences in customs, they might become strong competition against other countries. In 1958, six of the European countries --- Belgium, the Netherlands, Luxembourg, France, Germany and Italy got together and decided to cooperate. They called their group the European Economic Community, or the Common Market. These countries agreed to join their resources together. Within a few years, the European Economic Community had worked so well that its members were more prosperous than many other European nations. Soon, other nations began to realize the advantage of the Common Market. Today the Common Market includes most of the important countries in Western Europe. It is helping Western Europe to again take its place as a leader among the industrial nations of the world. Which statement is true?</td>\n",
       "      <td>The Common Market is only a political association.</td>\n",
       "      <td>The Common Market is an economic and political association</td>\n",
       "      <td>The Common Market is only an economic association</td>\n",
       "      <td>The Common Market is neither an economic association nor a political one.</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Below are reviews for three books and two book series. Each has been read and loved by students across the country.           The Outsiders          This book, first published in 1967. has become a classic for teens across the nation. It focuses on Ponyboy , who has been labeled all his life as a greaser. The greaser's opposing group is the \" socs \". kids who have lots of money and can break any rules without getting in trouble. As the novel develops, S. E. Hinton allows the reader to see exactly how these labels affect teens in both the greaser and the soc group.          If you've ever watched the movie The Outsiders, this story may sound familiar, as the movie was based on the book . The Outsiders gives teens a look into life in the 50's and 60's, offering timeless lessons that still apply to today's youth.          Out of the Dust          Any student interested in the Great Depression and the Dust Bowl should read Out of the Dust by Karen Hesse. Hesse is able to capture the mood and spirit of this era through the use of poetry. The main character of the book, Billie Jo, is growing up in Oklahoma, the heart of the Dust Bowl. Through free verse poetry, Billie Jo narrates  her tale of poverty and survival during this difficult time.          Out of the Dust is an excellent lesson in history . Due to the short length and writing style, the book is a quick but worthwhile read. By the end of the book, the reader is eager to start the story over again . Hesse is able to pack a lot of emotions and details into her short book , making the story very real and believable.           The Giver         The Giver depicts a perfect society in which citizens experience no pain, have never felt fear, and life is completely under control. However, as the reader progresses through the story, it's easy to see that this community is far from utopia  . Instead, through the experiences felt by the main character Jonas, the reader learns there is a missing from life in this world..         During the Ceremony of the Twelves, each 12--year --old is assigned their life --long career in the community . Jonas is chosen to be the Receiver of Memories, a very special job assigned to one person at a time . When Jonas receives his training . he learns many truths about his community that change how he feels about his life, making him determined to do something to change it .         The Giver is a good book for teens who enjoy science fiction and fantasy. The book makes you examine your own life, values, and beliefs, striving to find how you would define the perfect society.         Anne of Green Gables         This eight-book series depicts the life of Anne Shirley, an orphan that is adopted in Prince Edward Island, Canada . The books are set in the 1800s to the 1900s, the last one taking place during World War I. Anne is a loveable spirit who has many misfortunes and laughable experiences when growing up and going to college.          The Anne of Green Gables series is fun to read. creating a strong attachment to the reader and making the last book a bitter -sweet experience. Teenage girls who are looking for a female role model will love Anne Shirley.         Harry Potter         J. K. Rowling's Harry Potter series has sold more copies than any other series in history. The series , which includes seven books in all , fallows a boy wizard named Harry Potter.         Harry attends Hogwarts School of Witcheraft and Wizardy. The seven books follow Harry through seven years of wizarding school . During this time , readers experience the wizarding world through Harry's eyes and watch him make friends. Learn magic and fight a wizard.          The Harry Potter books are an enchanting read for all ages. No matter who you are. you will find yourself absorbed in the magical world created by J. K. Rowling. The greaser group may refer to those kids   _  .</td>\n",
       "      <td>who are poor in their lessons at school</td>\n",
       "      <td>who get along well with the soc group</td>\n",
       "      <td>who go between the poor and the rich children</td>\n",
       "      <td>who are poor and often get into trouble for breaking rules</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MANCHESTER, England -- Here's some good news that vegetarians   can really sink their teeth into: Researchers in UMA Group have developed genetically engineered fruit trees that produce real meat! Fruit from the new Meat Trees, developed by British scientists using the gene technology, is closely like ordinary grape-fruit. But when you cut the fruit open, inside is fresh beef!  \"Our trees may sound like something out of a science fiction movie, but it's really true,\" declares Dr. Vincent, director of the UMA Group, which created the amazing trees. \"Vegetarians have been complaining for years that in spite of their firm belief against eating meat, they still desire the taste of meat once in a while. Now they can have their cake and eat it too.\"  Although it's taken 12 years to develop the trees, the idea is simple. \"We take the genes from cattle and put them into the cells of grape-fruit trees,\" Dr. Vincent says. \"When the seeds grow into trees, they produce meat instead of ordinary fruit. You get the taste -- even the smell.\"  Those who've tried the meat agree it tastes like the real thing. \"I was a bit unwilling to believe at first when I sank my teeth into a hamburger after they told me it grew on a tree,\" says Londoner Mark, who took part in a taste-test. \"But it was juicy and delicious - nothing leafy about it at all.\" Meat Tree products could be on the market in Great Britain by the end of next year. Some vegetarians insist they should never eat meat -- even if it grew on a tree. Others love the idea. \"My mouth is watering already,\" says a devoted vegetarian of 20 years. According to what Dr. Vincent said, we know that   _  .</td>\n",
       "      <td>vegetarians like to make a cake and enjoy it later</td>\n",
       "      <td>the idea of Meat Trees came from a science fiction movie</td>\n",
       "      <td>vegetarians can eat meat from the new trees</td>\n",
       "      <td>vegetarians can taste and even smell fruit from Meat Trees</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Teenagers need family love and support at a time when lots of other things in their lives are changing . You can keep family relationships with your child strong through ordinary , everyday activities .      Adolescence   can be a difficult time ---your child is going through rapid physical changes as well as emotional ups and downs . Young people aren't sure where they fit , and they are still trying to work it out . Adolescence can also be a time when peer   influences and relationships can cause stress for teenagers and their families , and family support can be vital (=very important) to getting through these challenges.      During this time , your family can be a secure emotional base where your child feels loved and accepted , no matter what's going on in the rest of her life . Your family can build and support your child's self-belief , confidence and optimism .When your family set rules , boundaries and standard behaviour, you give your child a sense of consistency   and predictability . And believe it or not , your life experiences and knowledge can be really useful to your child ---she just might not always want to know that .      Supportive and close family relationships can reduce risky teenage behaviour, such as alcohol and drug abuse , and problems such as depression . They can also increase your child's feeling of being connected to school , and his desire to do well academically .      Strong family relationships can go a long way toward helping your teenager grow into a well-adjusted , considerate and caring adult .      Research suggests that just being around family is associated with fewer behaviour problems in teenagers. This could be as simple as being in the kitchen when your child's in her room , so she knows she could come and talk to you if she wanted to . Teenagers benefit from knowing that support is available , even though they might not be using it . According to the text , we can conclude   _   .</td>\n",
       "      <td>school plays less role in educating children</td>\n",
       "      <td>family can be vital for children to spend adolescence</td>\n",
       "      <td>teenagers sometimes can obey what parents say</td>\n",
       "      <td>parents should often help children to study at home</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alice is a busy girl. Now she is relaxing .She is watching the Friday night weather report on television .She likes sunny weather just like today. She wants to know what the weather will be like tomorrow. She's going to have a picnic  .This is what the reporter is saying, \"Good evening and welcome to evening weather report. We are going to have a very different weather across the country...\"Alice is sad .She doesn't like raining. Which one is right?    _  .</td>\n",
       "      <td>Alice is busy now</td>\n",
       "      <td>Alice doesn't like raining</td>\n",
       "      <td>Alice is going to the park</td>\n",
       "      <td>Alice is happy now</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The days of elderly women doing nothing but cooking huge meals on holidays are gone.Enter the Red Hat Society -a group holding the belief that old ladies should have fun. \"My grandmothers didn't do anything but keep house and serve everybody.They were programmed to do that,\" said Emily Cornett, head of a of the 7-year-old Red Hat Society. While men have long spent their time fishing and playing golf, women have sometimes seemed to become unnoticed as they age.But the generation now turning 50 is the baby boomers , and the same people who refused their parents' way of being young are now trying a new way of growing old. If you take into consideration feminism , a bit of spare money, and better health for most elderly, the Red Hat Society looks almost inevitable .In this society, women over 50 wear red hats and purple  clothes, while the women under 50 wear pink hats and light purple clothing. \"The organization took the idea from a poem by Jenny Joseph that begins: \"When I am an old woman, I shall wear purple.With a red hat which doesn't go,\" said Ellen Cooper, who founded the Red Hat Society in 1998.When the ladies started to wear the red hats, they attracted lots of attention. \"The point of this is that we need a rest from always doing something for someone else,\" Cooper saiD.\"Women feel so ashamed and sorry when they do something for themselves.\" This is why chapters are discouraged from raising money or doing anything useful.\"We're a ladies' play group.It couldn't be more simple,\" added Cooper's assistant Joe Heywood. It could be inferred from the text that members of the Red Hat Society are    _    .</td>\n",
       "      <td>interested in raising money for social work</td>\n",
       "      <td>programmers who can plan well for their future</td>\n",
       "      <td>believers in equality between men and women</td>\n",
       "      <td>good at cooking big meals and taking care of others</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Where is the biological magnification of pollutants most likely to be the greatest?</td>\n",
       "      <td>in an estuary</td>\n",
       "      <td>in an open ocean</td>\n",
       "      <td>at an intertidal zone</td>\n",
       "      <td>at a hydrothermal vent</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a93037ce-57a6-4ff1-bb82-3510cac88584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Question: {example['question']}\")\n",
    "    print(f\"  A - {example['A']}\")\n",
    "    print(f\"  B - {example['B']}\")\n",
    "    print(f\"  C - {example['C']}\")\n",
    "    print(f\"  D - {example['D']}\")\n",
    "    print(f\"\\nGround truth: option {example['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "01d2cc21-8dd9-4bcc-8862-2336fdd77346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were\n",
      "  A - Adams only.\n",
      "  B - Brooks only.\n",
      "  C - Case only.\n",
      "  D - Adams and Brooks\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a3d47-0aba-4478-a327-4dcf7b5a4375",
   "metadata": {},
   "source": [
    "## preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fedf7905-03e5-486e-a9b8-bef47ae43fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = 'allenai/longformer-base-4096'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a61d8ed0-e3b7-4b81-be3b-94c55187f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "options={'A':0, 'B':1, 'C':2, 'D':3}\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each questions four times to go with the four possibilities of second sentences.\n",
    "    first_sentences = [[context] * 4 for context in examples[\"question\"]]\n",
    "    \n",
    "    # Grab all option sentences possible for each question.\n",
    "    second_sentences = [[f\"{examples[option][i]}\" for option in options] for i in range(len(examples['question']))]\n",
    "    \n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "\n",
    "    # label idx\n",
    "    encoded_labels = [options[f'{label}'] for label in examples['answer']]\n",
    "    \n",
    "    # Un-flatten\n",
    "    output_dict={k: [v[i:i+4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}\n",
    "    output_dict['label'] = encoded_labels\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "05669cc4-27b6-4925-99fe-f2c925614372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 [95, 96, 95, 95]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "221c6b74-421e-4763-92a3-8ca2f1da7473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s>Peter sued Don for breach of contract. The court admitted testimony by Peter that Don and his wife quarreled frequently, a fact of no consequence to the lawsuit. Don seeks to testify in response that he and his wife never quarreled. The court</s></s>must permit Don to answer if he had objected to Peter's testimony.</s>\",\n",
       " \"<s>Peter sued Don for breach of contract. The court admitted testimony by Peter that Don and his wife quarreled frequently, a fact of no consequence to the lawsuit. Don seeks to testify in response that he and his wife never quarreled. The court</s></s>may permit Don to answer, whether or not he had objected to Peter's testimony. </s>\",\n",
       " \"<s>Peter sued Don for breach of contract. The court admitted testimony by Peter that Don and his wife quarreled frequently, a fact of no consequence to the lawsuit. Don seeks to testify in response that he and his wife never quarreled. The court</s></s>may permit Don to answer only if he had objected to Peter's testimony.</s>\",\n",
       " \"<s>Peter sued Don for breach of contract. The court admitted testimony by Peter that Don and his wife quarreled frequently, a fact of no consequence to the lawsuit. Don seeks to testify in response that he and his wife never quarreled. The court</s></s>cannot permit Don to answer, whether or not he had objected to Peter's testimony</s>\"]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3\n",
    "[tokenizer.decode(features[\"input_ids\"][idx][i]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d4085b3f-bc02-4575-8c82-b8e8b53f08c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed85e868fa8440708150daf98f3f513f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6264b91408bf4b35888201dd2955dbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/domain_specialized_llm/myenv/lib/python3.8/site-packages/datasets/dataset_dict.py:853\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 853\u001b[0m     {\n\u001b[1;32m    854\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    855\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[1;32m    856\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[1;32m    857\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[1;32m    858\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[1;32m    859\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[1;32m    860\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    861\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    862\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[1;32m    863\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    864\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    865\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    866\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    867\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m    868\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[1;32m    869\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[1;32m    870\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m    871\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[1;32m    872\u001b[0m         )\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    874\u001b[0m     }\n\u001b[1;32m    875\u001b[0m )\n",
      "File \u001b[0;32m~/domain_specialized_llm/myenv/lib/python3.8/site-packages/datasets/dataset_dict.py:854\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    853\u001b[0m     {\n\u001b[0;32m--> 854\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    874\u001b[0m     }\n\u001b[1;32m    875\u001b[0m )\n",
      "File \u001b[0;32m~/domain_specialized_llm/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/domain_specialized_llm/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/domain_specialized_llm/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:3097\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3091\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m   3092\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3093\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3094\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3095\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3096\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3097\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3098\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3099\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/domain_specialized_llm/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:3474\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3470\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3472\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3473\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3474\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3478\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3479\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3480\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3483\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/domain_specialized_llm/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:3353\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3352\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3353\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3355\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3356\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3357\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[114], line 18\u001b[0m, in \u001b[0;36mpreprocess_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     15\u001b[0m tokenized_examples \u001b[38;5;241m=\u001b[39m tokenizer(first_sentences, second_sentences, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# label idx\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m encoded_labels \u001b[38;5;241m=\u001b[39m [options[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Un-flatten\u001b[39;00m\n\u001b[1;32m     21\u001b[0m output_dict\u001b[38;5;241m=\u001b[39m{k: [v[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(v), \u001b[38;5;241m4\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tokenized_examples\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[0;32mIn[114], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m tokenized_examples \u001b[38;5;241m=\u001b[39m tokenizer(first_sentences, second_sentences, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# label idx\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m encoded_labels \u001b[38;5;241m=\u001b[39m [\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlabel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Un-flatten\u001b[39;00m\n\u001b[1;32m     21\u001b[0m output_dict\u001b[38;5;241m=\u001b[39m{k: [v[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(v), \u001b[38;5;241m4\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tokenized_examples\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mKeyError\u001b[0m: '3'"
     ]
    }
   ],
   "source": [
    "encoded_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7bbdd-2167-4d0d-ac12-1cfd414f22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf43fb4-e7df-46e2-89c3-aec27770a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_ckpt.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79304cf0-0c3a-4558-b6d1-94843252e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e25c092-7cbd-43bf-a23c-a03bd6e46f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is true for a type-Ia (\"type one-a\") supernova?',\n",
       " 'A': 'This type occurs in binary systems.',\n",
       " 'B': 'This type occurs in young galaxies.',\n",
       " 'C': 'This type produces gamma-ray bursts.',\n",
       " 'D': 'This type produces high amounts of X-rays.',\n",
       " 'answer': 'A',\n",
       " 'input_ids': [[0,\n",
       "   2264,\n",
       "   16,\n",
       "   1528,\n",
       "   13,\n",
       "   10,\n",
       "   1907,\n",
       "   12,\n",
       "   100,\n",
       "   102,\n",
       "   6697,\n",
       "   12528,\n",
       "   65,\n",
       "   12,\n",
       "   102,\n",
       "   8070,\n",
       "   2422,\n",
       "   38823,\n",
       "   116,\n",
       "   2,\n",
       "   2,\n",
       "   713,\n",
       "   1907,\n",
       "   11493,\n",
       "   11,\n",
       "   32771,\n",
       "   1743,\n",
       "   4,\n",
       "   2],\n",
       "  [0,\n",
       "   2264,\n",
       "   16,\n",
       "   1528,\n",
       "   13,\n",
       "   10,\n",
       "   1907,\n",
       "   12,\n",
       "   100,\n",
       "   102,\n",
       "   6697,\n",
       "   12528,\n",
       "   65,\n",
       "   12,\n",
       "   102,\n",
       "   8070,\n",
       "   2422,\n",
       "   38823,\n",
       "   116,\n",
       "   2,\n",
       "   2,\n",
       "   713,\n",
       "   1907,\n",
       "   11493,\n",
       "   11,\n",
       "   664,\n",
       "   30948,\n",
       "   4,\n",
       "   2],\n",
       "  [0,\n",
       "   2264,\n",
       "   16,\n",
       "   1528,\n",
       "   13,\n",
       "   10,\n",
       "   1907,\n",
       "   12,\n",
       "   100,\n",
       "   102,\n",
       "   6697,\n",
       "   12528,\n",
       "   65,\n",
       "   12,\n",
       "   102,\n",
       "   8070,\n",
       "   2422,\n",
       "   38823,\n",
       "   116,\n",
       "   2,\n",
       "   2,\n",
       "   713,\n",
       "   1907,\n",
       "   9108,\n",
       "   42685,\n",
       "   12,\n",
       "   5022,\n",
       "   28740,\n",
       "   4,\n",
       "   2],\n",
       "  [0,\n",
       "   2264,\n",
       "   16,\n",
       "   1528,\n",
       "   13,\n",
       "   10,\n",
       "   1907,\n",
       "   12,\n",
       "   100,\n",
       "   102,\n",
       "   6697,\n",
       "   12528,\n",
       "   65,\n",
       "   12,\n",
       "   102,\n",
       "   8070,\n",
       "   2422,\n",
       "   38823,\n",
       "   116,\n",
       "   2,\n",
       "   2,\n",
       "   713,\n",
       "   1907,\n",
       "   9108,\n",
       "   239,\n",
       "   5353,\n",
       "   9,\n",
       "   1577,\n",
       "   12,\n",
       "   24192,\n",
       "   4,\n",
       "   2]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b4ae426c-2275-4282-9651-83a46c251e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'A', 'B', 'C', 'D', 'answer', 'input_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 453\n",
       "})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9908100-0f69-4e83-ad4b-f245f210d986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[0, 2264, 16, 1528, 13, 10, 1907, 12, 100, 102, 6697, 12528, 65, 12, 102, 8070, 2422, 38823, 116, 2, 2, 713, 1907, 11493, 11, 32771, 1743, 4, 2], [0, 2264, 16, 1528, 13, 10, 1907, 12, 100, 102, 6697, 12528, 65, 12, 102, 8070, 2422, 38823, 116, 2, 2, 713, 1907, 11493, 11, 664, 30948, 4, 2], [0, 2264, 16, 1528, 13, 10, 1907, 12, 100, 102, 6697, 12528, 65, 12, 102, 8070, 2422, 38823, 116, 2, 2, 713, 1907, 9108, 42685, 12, 5022, 28740, 4, 2], [0, 2264, 16, 1528, 13, 10, 1907, 12, 100, 102, 6697, 12528, 65, 12, 102, 8070, 2422, 38823, 116, 2, 2, 713, 1907, 9108, 239, 5353, 9, 1577, 12, 24192, 4, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "print(features[0])\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15ef10db-ff4e-4c5d-bdd5-d3ae76af773c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>If you know both the actual brightness of an object and its apparent brightness from your location then with no other information you can estimate:</s></s>Its speed relative to you</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>If you know both the actual brightness of an object and its apparent brightness from your location then with no other information you can estimate:</s></s>Its composition</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>If you know both the actual brightness of an object and its apparent brightness from your location then with no other information you can estimate:</s></s>Its size</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>If you know both the actual brightness of an object and its apparent brightness from your location then with no other information you can estimate:</s></s>Its distance from you</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][1][i].tolist()) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c6284824-7b9c-447c-bf17-928e180cd759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the second most common element in the solar system?\n",
      "  A - Iron\n",
      "  B - Hydrogen\n",
      "  C - Methane\n",
      "  D - Helium\n",
      "\n",
      "Ground truth: option D\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4e5a96d9-bf90-4fe5-814c-78064901d87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3583c-8050-40c8-a195-a261e1351e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
