{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OpenBook DeBERTaV3-Large with an updated model\n",
    "\n",
    "This work is based on the great [work](https://www.kaggle.com/code/nlztrk/openbook-debertav3-large-baseline-single-model) of [nlztrk](https://www.kaggle.com/nlztrk).\n",
    "\n",
    "I trained a model offline using the dataset I shared [here](https://www.kaggle.com/datasets/mgoksu/llm-science-exam-dataset-w-context). I just added my model to the original notebook. The model is available [here](https://www.kaggle.com/datasets/mgoksu/llm-science-run-context-2).\n",
    "\n",
    "I also addressed the problem of [CSV Not Found at submission](https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/434228) with this notebook by clipping the context like so:\n",
    "\n",
    "`test_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:1500]) + \" #### \" +  test_df[\"prompt\"]`\n",
    "\n",
    "You can probably get more than 1500 without getting an OOM."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# installing offline dependencies\n",
    "!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n",
    "!pip install -U /kaggle/working/sentence-transformers\n",
    "!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n",
    "\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl"
   ],
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 126.809817,
     "end_time": "2023-08-14T10:09:22.925969",
     "exception": false,
     "start_time": "2023-08-14T10:07:16.116152",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:51:33.755537Z",
     "iopub.execute_input": "2023-09-13T06:51:33.756041Z",
     "iopub.status.idle": "2023-09-13T06:53:37.178167Z",
     "shell.execute_reply.started": "2023-09-13T06:51:33.756013Z",
     "shell.execute_reply": "2023-09-13T06:53:37.176923Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Processing /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\nProcessing ./sentence-transformers\n  Preparing metadata (setup.py) ... \u001B[?25ldone\n\u001B[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.30.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.65.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.11.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126134 sha256=7e7af9bc944f1a02a3ad0b7df94ff7cd14139382b31fe88c90db271778cbd4a2\n  Stored in directory: /root/.cache/pip/wheels/6c/ea/76/d9a930b223b1d3d5d6aff69458725316b0fe205b854faf1812\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\nProcessing /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\nInstalling collected packages: blingfire\nSuccessfully installed blingfire-0.1.8\nProcessing /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.2\n    Uninstalling transformers-4.30.2:\n      Successfully uninstalled transformers-4.30.2\nSuccessfully installed transformers-4.31.0\nProcessing /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\nInstalling collected packages: peft\nSuccessfully installed peft-0.4.0\nProcessing /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\nInstalling collected packages: datasets\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\nSuccessfully installed datasets-2.14.3\nProcessing /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl\nInstalling collected packages: trl\nSuccessfully installed trl-0.5.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import blingfire as bf\n",
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import faiss\n",
    "from faiss import write_index, read_index\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "papermill": {
     "duration": 8.534957,
     "end_time": "2023-08-14T10:09:31.474781",
     "exception": false,
     "start_time": "2023-08-14T10:09:22.939824",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:54:04.493228Z",
     "iopub.execute_input": "2023-09-13T06:54:04.493629Z",
     "iopub.status.idle": "2023-09-13T06:54:18.532273Z",
     "shell.execute_reply.started": "2023-09-13T06:54:04.493597Z",
     "shell.execute_reply": "2023-09-13T06:54:18.531285Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def process_documents(documents: Iterable[str],\n",
    "                      document_ids: Iterable,\n",
    "                      split_sentences: bool = True,\n",
    "                      filter_len: int = 7,\n",
    "                      disable_progress_bar: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main helper function to process documents from the EMR.\n",
    "\n",
    "    :param documents: Iterable containing documents which are strings\n",
    "    :param document_ids: Iterable containing document unique identifiers\n",
    "    :param document_type: String denoting the document type to be processed\n",
    "    :param document_sections: List of sections for a given document type to process\n",
    "    :param split_sentences: Flag to determine whether to further split sections into sentences\n",
    "    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n",
    "    :param disable_progress_bar: Flag to disable tqdm progress bar\n",
    "    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n",
    "    \"\"\"\n",
    "    \n",
    "    df = sectionize_documents(documents, document_ids, disable_progress_bar)\n",
    "\n",
    "    if split_sentences:\n",
    "        df = sentencize(df.text.values, \n",
    "                        df.document_id.values,\n",
    "                        df.offset.values, \n",
    "                        filter_len, \n",
    "                        disable_progress_bar)\n",
    "    return df\n",
    "\n",
    "\n",
    "def sectionize_documents(documents: Iterable[str],\n",
    "                         document_ids: Iterable,\n",
    "                         disable_progress_bar: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Obtains the sections of the imaging reports and returns only the \n",
    "    selected sections (defaults to FINDINGS, IMPRESSION, and ADDENDUM).\n",
    "\n",
    "    :param documents: Iterable containing documents which are strings\n",
    "    :param document_ids: Iterable containing document unique identifiers\n",
    "    :param disable_progress_bar: Flag to disable tqdm progress bar\n",
    "    :return: Pandas DataFrame containing the columns `document_id`, `text`, `offset`\n",
    "    \"\"\"\n",
    "    processed_documents = []\n",
    "    for document_id, document in tqdm(zip(document_ids, documents), total=len(documents), disable=disable_progress_bar):\n",
    "        row = {}\n",
    "        text, start, end = (document, 0, len(document))\n",
    "        row['document_id'] = document_id\n",
    "        row['text'] = text\n",
    "        row['offset'] = (start, end)\n",
    "\n",
    "        processed_documents.append(row)\n",
    "\n",
    "    _df = pd.DataFrame(processed_documents)\n",
    "    if _df.shape[0] > 0:\n",
    "        return _df.sort_values(['document_id', 'offset']).reset_index(drop=True)\n",
    "    else:\n",
    "        return _df\n",
    "\n",
    "\n",
    "def sentencize(documents: Iterable[str],\n",
    "               document_ids: Iterable,\n",
    "               offsets: Iterable[tuple[int, int]],\n",
    "               filter_len: int = 7,\n",
    "               disable_progress_bar: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Split a document into sentences. Can be used with `sectionize_documents`\n",
    "    to further split documents into more manageable pieces. Takes in offsets\n",
    "    to ensure that after splitting, the sentences can be matched to the\n",
    "    location in the original documents.\n",
    "\n",
    "    :param documents: Iterable containing documents which are strings\n",
    "    :param document_ids: Iterable containing document unique identifiers\n",
    "    :param offsets: Iterable tuple of the start and end indices\n",
    "    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n",
    "    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n",
    "    \"\"\"\n",
    "\n",
    "    document_sentences = []\n",
    "    for document, document_id, offset in tqdm(zip(documents, document_ids, offsets), total=len(documents), disable=disable_progress_bar):\n",
    "        try:\n",
    "            _, sentence_offsets = bf.text_to_sentences_and_offsets(document)\n",
    "            for o in sentence_offsets:\n",
    "                if o[1]-o[0] > filter_len:\n",
    "                    sentence = document[o[0]:o[1]]\n",
    "                    abs_offsets = (o[0]+offset[0], o[1]+offset[0])\n",
    "                    row = {}\n",
    "                    row['document_id'] = document_id\n",
    "                    row['text'] = sentence\n",
    "                    row['offset'] = abs_offsets\n",
    "                    document_sentences.append(row)\n",
    "        except:\n",
    "            continue\n",
    "    return pd.DataFrame(document_sentences)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.034054,
     "end_time": "2023-08-14T10:09:31.574046",
     "exception": false,
     "start_time": "2023-08-14T10:09:31.539992",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:54:50.625402Z",
     "iopub.execute_input": "2023-09-13T06:54:50.625758Z",
     "iopub.status.idle": "2023-09-13T06:54:50.644979Z",
     "shell.execute_reply.started": "2023-09-13T06:54:50.625729Z",
     "shell.execute_reply": "2023-09-13T06:54:50.643822Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "SIM_MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\n",
    "DEVICE = 0\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "WIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\n",
    "wiki_files = os.listdir(WIKI_PATH)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.036342,
     "end_time": "2023-08-14T10:09:31.623595",
     "exception": false,
     "start_time": "2023-08-14T10:09:31.587253",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:54:52.455586Z",
     "iopub.execute_input": "2023-09-13T06:54:52.455988Z",
     "iopub.status.idle": "2023-09-13T06:54:52.465712Z",
     "shell.execute_reply.started": "2023-09-13T06:54:52.455957Z",
     "shell.execute_reply": "2023-09-13T06:54:52.464547Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Relevant Title Retrieval"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "trn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\").drop(\"id\", 1)\n",
    "trn.head()"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.058533,
     "end_time": "2023-08-14T10:09:31.695383",
     "exception": false,
     "start_time": "2023-08-14T10:09:31.63685",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:54:55.199734Z",
     "iopub.execute_input": "2023-09-13T06:54:55.200443Z",
     "iopub.status.idle": "2023-09-13T06:54:55.236951Z",
     "shell.execute_reply.started": "2023-09-13T06:54:55.200408Z",
     "shell.execute_reply": "2023-09-13T06:54:55.235880Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_28/2609134301.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n  trn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\").drop(\"id\", 1)\n",
     "output_type": "stream"
    },
    {
     "execution_count": 5,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                              prompt  \\\n0  Which of the following statements accurately d...   \n1  Which of the following is an accurate definiti...   \n2  Which of the following statements accurately d...   \n3  What is the significance of regularization in ...   \n4  Which of the following statements accurately d...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E  \n0  MOND is a theory that eliminates the observed ...  \n1  Dynamic scaling refers to the evolution of sel...  \n2  The triskeles symbol is a representation of th...  \n3  Regularizing the mass-energy of an electron wi...  \n4  The angular spacing of features in the diffrac...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = SentenceTransformer(SIM_MODEL, device='cuda')\n",
    "model.max_seq_length = MAX_LENGTH\n",
    "model = model.half()"
   ],
   "metadata": {
    "papermill": {
     "duration": 13.282604,
     "end_time": "2023-08-14T10:09:44.992949",
     "exception": false,
     "start_time": "2023-08-14T10:09:31.710345",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:54:55.461821Z",
     "iopub.execute_input": "2023-09-13T06:54:55.462192Z",
     "iopub.status.idle": "2023-09-13T06:54:57.238922Z",
     "shell.execute_reply.started": "2023-09-13T06:54:55.462162Z",
     "shell.execute_reply": "2023-09-13T06:54:57.237746Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sentence_index = read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")"
   ],
   "metadata": {
    "papermill": {
     "duration": 95.926417,
     "end_time": "2023-08-14T10:11:20.934445",
     "exception": false,
     "start_time": "2023-08-14T10:09:45.008028",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:54:58.965100Z",
     "iopub.execute_input": "2023-09-13T06:54:58.965464Z",
     "iopub.status.idle": "2023-09-13T06:56:36.435162Z",
     "shell.execute_reply.started": "2023-09-13T06:54:58.965434Z",
     "shell.execute_reply": "2023-09-13T06:56:36.434146Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## question에 해당하는 prompt만 가지고 embedding을 만듦\n",
    "\n",
    "prompt_embeddings = model.encode(trn.prompt.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\n",
    "prompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n",
    "_ = gc.collect()"
   ],
   "metadata": {
    "papermill": {
     "duration": 10.891104,
     "end_time": "2023-08-14T10:11:31.84869",
     "exception": false,
     "start_time": "2023-08-14T10:11:20.957586",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:57:32.250054Z",
     "iopub.execute_input": "2023-09-13T06:57:32.250417Z",
     "iopub.status.idle": "2023-09-13T06:57:39.852960Z",
     "shell.execute_reply.started": "2023-09-13T06:57:32.250389Z",
     "shell.execute_reply": "2023-09-13T06:57:39.852014Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Batches:   0%|          | 0/25 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f21b95e921d2427c9799d6dbb79bae3f"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## Get the top 6 pages that are likely to contain the topic of interest\n",
    "## question embedding과 가장 유사한 index를 뽑는다.\n",
    "\n",
    "search_score, search_index = sentence_index.search(prompt_embeddings, 6)"
   ],
   "metadata": {
    "papermill": {
     "duration": 23.339585,
     "end_time": "2023-08-14T10:11:55.247556",
     "exception": false,
     "start_time": "2023-08-14T10:11:31.907971",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:57:43.045158Z",
     "iopub.execute_input": "2023-09-13T06:57:43.045891Z",
     "iopub.status.idle": "2023-09-13T06:58:06.589366Z",
     "shell.execute_reply.started": "2023-09-13T06:57:43.045831Z",
     "shell.execute_reply": "2023-09-13T06:58:06.588531Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## Save memory - delete sentence_index since it is no longer necessary\n",
    "del sentence_index\n",
    "del prompt_embeddings\n",
    "_ = gc.collect()\n",
    "libc.malloc_trim(0)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.877305,
     "end_time": "2023-08-14T10:11:56.145444",
     "exception": false,
     "start_time": "2023-08-14T10:11:55.268139",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T06:58:06.591049Z",
     "iopub.execute_input": "2023-09-13T06:58:06.591610Z",
     "iopub.status.idle": "2023-09-13T06:58:07.457996Z",
     "shell.execute_reply.started": "2023-09-13T06:58:06.591576Z",
     "shell.execute_reply": "2023-09-13T06:58:07.456768Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "execution_count": 10,
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "search_score"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-13T06:59:30.597088Z",
     "iopub.execute_input": "2023-09-13T06:59:30.597453Z",
     "iopub.status.idle": "2023-09-13T06:59:30.606018Z",
     "shell.execute_reply.started": "2023-09-13T06:59:30.597425Z",
     "shell.execute_reply": "2023-09-13T06:59:30.604845Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "execution_count": 11,
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.8242638 , 0.94124174, 0.98174715, 0.9998764 , 1.0061644 ,\n        1.0151274 ],\n       [0.38855505, 0.79623413, 0.81992173, 0.8434491 , 0.8605889 ,\n        0.8640441 ],\n       [0.76912475, 0.9601331 , 0.9661969 , 0.97057855, 1.0014999 ,\n        1.0034419 ],\n       ...,\n       [0.98541725, 1.0154207 , 1.0192184 , 1.035223  , 1.0528091 ,\n        1.0543661 ],\n       [0.8719076 , 0.87460625, 0.874792  , 0.8862244 , 0.88910675,\n        0.9024073 ],\n       [0.6469635 , 0.69145715, 0.7300302 , 0.78801167, 0.8041347 ,\n        0.84459054]], dtype=float32)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "search_index"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-13T06:59:42.793530Z",
     "iopub.execute_input": "2023-09-13T06:59:42.793911Z",
     "iopub.status.idle": "2023-09-13T06:59:42.800617Z",
     "shell.execute_reply.started": "2023-09-13T06:59:42.793879Z",
     "shell.execute_reply": "2023-09-13T06:59:42.799703Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "execution_count": 12,
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[3573843, 4906500, 1830796, 3408267, 3260726, 1429137],\n       [1431454, 5135549, 5135229, 5135548, 1431498, 5094879],\n       [5819511, 5806421, 5810490, 5815906,  885478, 5845219],\n       ...,\n       [4799422, 1114209, 1059625, 3487902, 1106851, 1059279],\n       [4557948, 2958565, 3795798,   51689, 3795692, 4795172],\n       [1464446,  363737, 1464453, 1464449, 4831426,  956354]])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting Sentences from the Relevant Titles"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_parquet(\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\",\n",
    "                     columns=['id', 'file'])"
   ],
   "metadata": {
    "papermill": {
     "duration": 5.737408,
     "end_time": "2023-08-14T10:12:01.897408",
     "exception": false,
     "start_time": "2023-08-14T10:11:56.16",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:01:43.163475Z",
     "iopub.execute_input": "2023-09-13T07:01:43.163873Z",
     "iopub.status.idle": "2023-09-13T07:01:47.480867Z",
     "shell.execute_reply.started": "2023-09-13T07:01:43.163824Z",
     "shell.execute_reply": "2023-09-13T07:01:47.479835Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## Get the article and associated file location using the index\n",
    "wikipedia_file_data = []\n",
    "\n",
    "for i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n",
    "    scr_idx = idx\n",
    "    _df = df.loc[scr_idx].copy()\n",
    "    _df['prompt_id'] = i\n",
    "    wikipedia_file_data.append(_df)\n",
    "wikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\n",
    "wikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)\n",
    "\n",
    "## Save memory - delete df since it is no longer necessary\n",
    "del df\n",
    "_ = gc.collect()\n",
    "libc.malloc_trim(0)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.799872,
     "end_time": "2023-08-14T10:12:02.712752",
     "exception": false,
     "start_time": "2023-08-14T10:12:01.91288",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:01:47.484676Z",
     "iopub.execute_input": "2023-09-13T07:01:47.484990Z",
     "iopub.status.idle": "2023-09-13T07:01:48.222710Z",
     "shell.execute_reply.started": "2023-09-13T07:01:47.484963Z",
     "shell.execute_reply": "2023-09-13T07:01:48.221778Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e23020a772b430495d245502b267a53"
      }
     },
     "metadata": {}
    },
    {
     "execution_count": 14,
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## top 6의 article이 있는 file을 담고 있다. \n",
    "\n",
    "wikipedia_file_data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-13T07:02:43.489746Z",
     "iopub.execute_input": "2023-09-13T07:02:43.490677Z",
     "iopub.status.idle": "2023-09-13T07:02:43.505053Z",
     "shell.execute_reply.started": "2023-09-13T07:02:43.490632Z",
     "shell.execute_reply": "2023-09-13T07:02:43.503913Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "execution_count": 15,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            id  prompt_id       file\n0         1141         36  a.parquet\n1         1141        151  a.parquet\n2     11963992        185  a.parquet\n3     11963992        191  a.parquet\n4         1200         63  a.parquet\n...        ...        ...        ...\n1195  31557501         49  y.parquet\n1196     34341        179  y.parquet\n1197  47610211         49  y.parquet\n1198   5187243        103  y.parquet\n1199     34527        103  z.parquet\n\n[1200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1141</td>\n      <td>36</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1141</td>\n      <td>151</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11963992</td>\n      <td>185</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11963992</td>\n      <td>191</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1200</td>\n      <td>63</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>31557501</td>\n      <td>49</td>\n      <td>y.parquet</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>34341</td>\n      <td>179</td>\n      <td>y.parquet</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>47610211</td>\n      <td>49</td>\n      <td>y.parquet</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>5187243</td>\n      <td>103</td>\n      <td>y.parquet</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>34527</td>\n      <td>103</td>\n      <td>z.parquet</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows × 3 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## Get the full text data\n",
    "wiki_text_data = []\n",
    "\n",
    "for file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n",
    "    _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data['file']==file]['id'].tolist()]\n",
    "    _df = pd.read_parquet(f\"{WIKI_PATH}/{file}\", columns=['id', 'text'])\n",
    "\n",
    "    _df_temp = _df[_df['id'].isin(_id)].copy()\n",
    "    del _df\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)\n",
    "    wiki_text_data.append(_df_temp)\n",
    "wiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)\n",
    "_ = gc.collect()"
   ],
   "metadata": {
    "papermill": {
     "duration": 303.981049,
     "end_time": "2023-08-14T10:17:06.710072",
     "exception": false,
     "start_time": "2023-08-14T10:12:02.729023",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:03:08.680596Z",
     "iopub.execute_input": "2023-09-13T07:03:08.680991Z",
     "iopub.status.idle": "2023-09-13T07:07:44.745051Z",
     "shell.execute_reply.started": "2023-09-13T07:03:08.680958Z",
     "shell.execute_reply": "2023-09-13T07:07:44.744016Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/28 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37c73492724a44a08d0b5b353b656e13"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "wiki_text_data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-13T07:20:11.223374Z",
     "iopub.execute_input": "2023-09-13T07:20:11.223737Z",
     "iopub.status.idle": "2023-09-13T07:20:11.237053Z",
     "shell.execute_reply.started": "2023-09-13T07:20:11.223708Z",
     "shell.execute_reply": "2023-09-13T07:20:11.236050Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": [
    {
     "execution_count": 22,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            id                                               text\n0      5259071  A Briefer History of Time is a 2006 popular-sc...\n1     65293114  A History of the Theories of Aether and Electr...\n2      1550261  The American Petroleum Institute gravity, or A...\n3      4389619  In superconductivity, fluxon (also called a Ab...\n4         1963  Absolute magnitude () is a measure of the lumi...\n...        ...                                                ...\n1138  47610211                                                   \n1139   5187243  A yellow hypergiant (YHG) is a massive star wi...\n1140   1217512  Yellow sun or Yellow Sun may refer to: *Yellow...\n1141   1063160  was a Japanese-American physicist and professo...\n1142     34527  The zodiacal light (also called false dawn whe...\n\n[1143 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5259071</td>\n      <td>A Briefer History of Time is a 2006 popular-sc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>65293114</td>\n      <td>A History of the Theories of Aether and Electr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1550261</td>\n      <td>The American Petroleum Institute gravity, or A...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4389619</td>\n      <td>In superconductivity, fluxon (also called a Ab...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1963</td>\n      <td>Absolute magnitude () is a measure of the lumi...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1138</th>\n      <td>47610211</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1139</th>\n      <td>5187243</td>\n      <td>A yellow hypergiant (YHG) is a massive star wi...</td>\n    </tr>\n    <tr>\n      <th>1140</th>\n      <td>1217512</td>\n      <td>Yellow sun or Yellow Sun may refer to: *Yellow...</td>\n    </tr>\n    <tr>\n      <th>1141</th>\n      <td>1063160</td>\n      <td>was a Japanese-American physicist and professo...</td>\n    </tr>\n    <tr>\n      <th>1142</th>\n      <td>34527</td>\n      <td>The zodiacal light (also called false dawn whe...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1143 rows × 2 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## Parse documents into sentences\n",
    "processed_wiki_text_data = process_documents(wiki_text_data.text.values, wiki_text_data.id.values)"
   ],
   "metadata": {
    "papermill": {
     "duration": 4.491281,
     "end_time": "2023-08-14T10:17:11.220342",
     "exception": false,
     "start_time": "2023-08-14T10:17:06.729061",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:17:29.592897Z",
     "iopub.execute_input": "2023-09-13T07:17:29.593287Z",
     "iopub.status.idle": "2023-09-13T07:17:37.806212Z",
     "shell.execute_reply.started": "2023-09-13T07:17:29.593239Z",
     "shell.execute_reply": "2023-09-13T07:17:37.805100Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1143 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc46088b52f04341a30dcb8eaa2df1e1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1143 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac7a63176a4a4ac2b85cd898f74af584"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "processed_wiki_text_data ## offset이 의미하는 바가 뭐지?"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-13T07:21:49.768541Z",
     "iopub.execute_input": "2023-09-13T07:21:49.769132Z",
     "iopub.status.idle": "2023-09-13T07:21:49.785626Z",
     "shell.execute_reply.started": "2023-09-13T07:21:49.769098Z",
     "shell.execute_reply": "2023-09-13T07:21:49.784593Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "execution_count": 25,
     "output_type": "execute_result",
     "data": {
      "text/plain": "      document_id                                               text  \\\n0        10087606  In group theory, geometry, representation theo...   \n1        10087606  For example, as transformations of an object i...   \n2        10087606  Such symmetry operations are performed with re...   \n3        10087606  In the context of molecular symmetry, a symmet...   \n4        10087606  Two basic facts follow from this definition, w...   \n...           ...                                                ...   \n58845     9962772                                         Mit Beitr.   \n58846     9962772  Barth, 1957) == Selected publications == *Carl...   \n58847     9962772  (Received 7 September 1920, published in issue...   \n58848     9962772  Volume 1 Part 2 The Quantum Theory of Planck, ...   \n58849     9962772  (Springer, 1982) *Walker, Mark German National...   \n\n             offset  \n0          (0, 207)  \n1        (208, 329)  \n2        (330, 441)  \n3        (442, 631)  \n4        (632, 709)  \n...             ...  \n58845  (6031, 6041)  \n58846  (6049, 6223)  \n58847  (6224, 7033)  \n58848  (7034, 7169)  \n58849  (7170, 7553)  \n\n[58850 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document_id</th>\n      <th>text</th>\n      <th>offset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10087606</td>\n      <td>In group theory, geometry, representation theo...</td>\n      <td>(0, 207)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10087606</td>\n      <td>For example, as transformations of an object i...</td>\n      <td>(208, 329)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10087606</td>\n      <td>Such symmetry operations are performed with re...</td>\n      <td>(330, 441)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10087606</td>\n      <td>In the context of molecular symmetry, a symmet...</td>\n      <td>(442, 631)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10087606</td>\n      <td>Two basic facts follow from this definition, w...</td>\n      <td>(632, 709)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58845</th>\n      <td>9962772</td>\n      <td>Mit Beitr.</td>\n      <td>(6031, 6041)</td>\n    </tr>\n    <tr>\n      <th>58846</th>\n      <td>9962772</td>\n      <td>Barth, 1957) == Selected publications == *Carl...</td>\n      <td>(6049, 6223)</td>\n    </tr>\n    <tr>\n      <th>58847</th>\n      <td>9962772</td>\n      <td>(Received 7 September 1920, published in issue...</td>\n      <td>(6224, 7033)</td>\n    </tr>\n    <tr>\n      <th>58848</th>\n      <td>9962772</td>\n      <td>Volume 1 Part 2 The Quantum Theory of Planck, ...</td>\n      <td>(7034, 7169)</td>\n    </tr>\n    <tr>\n      <th>58849</th>\n      <td>9962772</td>\n      <td>(Springer, 1982) *Walker, Mark German National...</td>\n      <td>(7170, 7553)</td>\n    </tr>\n  </tbody>\n</table>\n<p>58850 rows × 3 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## Get embeddings of the wiki text data\n",
    "wiki_data_embeddings = model.encode(processed_wiki_text_data.text,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    device=DEVICE,\n",
    "                                    show_progress_bar=True,\n",
    "                                    convert_to_tensor=True,\n",
    "                                    normalize_embeddings=True)#.half()\n",
    "wiki_data_embeddings = wiki_data_embeddings.detach().cpu().numpy()"
   ],
   "metadata": {
    "papermill": {
     "duration": 25.110593,
     "end_time": "2023-08-14T10:17:36.348422",
     "exception": false,
     "start_time": "2023-08-14T10:17:11.237829",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:18:19.520579Z",
     "iopub.execute_input": "2023-09-13T07:18:19.521983Z",
     "iopub.status.idle": "2023-09-13T07:19:23.505274Z",
     "shell.execute_reply.started": "2023-09-13T07:18:19.521934Z",
     "shell.execute_reply": "2023-09-13T07:19:23.504190Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Batches:   0%|          | 0/7357 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61c17f4c9eab44bb83517e19232261c5"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "_ = gc.collect()"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.315807,
     "end_time": "2023-08-14T10:17:36.679867",
     "exception": false,
     "start_time": "2023-08-14T10:17:36.36406",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:19:31.526708Z",
     "iopub.execute_input": "2023-09-13T07:19:31.527810Z",
     "iopub.status.idle": "2023-09-13T07:19:31.852339Z",
     "shell.execute_reply.started": "2023-09-13T07:19:31.527760Z",
     "shell.execute_reply": "2023-09-13T07:19:31.851057Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## Combine all answers\n",
    "trn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\n",
    "\n",
    "\n",
    "## Search using the prompt and answers to guide the search\n",
    "trn['prompt_answer_stem'] = trn['prompt'] + \" \" + trn['answer_all']"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.034767,
     "end_time": "2023-08-14T10:17:36.730378",
     "exception": false,
     "start_time": "2023-08-14T10:17:36.695611",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:19:33.323291Z",
     "iopub.execute_input": "2023-09-13T07:19:33.324199Z",
     "iopub.status.idle": "2023-09-13T07:19:33.338878Z",
     "shell.execute_reply.started": "2023-09-13T07:19:33.324164Z",
     "shell.execute_reply": "2023-09-13T07:19:33.337593Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "question_embeddings = model.encode(trn.prompt_answer_stem.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\n",
    "question_embeddings = question_embeddings.detach().cpu().numpy()"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.431343,
     "end_time": "2023-08-14T10:17:37.177862",
     "exception": false,
     "start_time": "2023-08-14T10:17:36.746519",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:19:35.002295Z",
     "iopub.execute_input": "2023-09-13T07:19:35.002679Z",
     "iopub.status.idle": "2023-09-13T07:19:35.418464Z",
     "shell.execute_reply.started": "2023-09-13T07:19:35.002645Z",
     "shell.execute_reply": "2023-09-13T07:19:35.415621Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Batches:   0%|          | 0/25 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d86807ea0094c4fb331f6753e02eb73"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting Matching Prompt-Sentence Pairs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "## Parameter to determine how many relevant sentences to include\n",
    "NUM_SENTENCES_INCLUDE = 20\n",
    "\n",
    "## List containing just Context\n",
    "contexts = []\n",
    "\n",
    "for r in tqdm(trn.itertuples(), total=len(trn)):\n",
    "\n",
    "    prompt_id = r.Index\n",
    "\n",
    "    prompt_indices = processed_wiki_text_data[processed_wiki_text_data['document_id'].isin(wikipedia_file_data[wikipedia_file_data['prompt_id']==prompt_id]['id'].values)].index.values\n",
    "\n",
    "    if prompt_indices.shape[0] > 0:\n",
    "        prompt_index = faiss.index_factory(wiki_data_embeddings.shape[1], \"Flat\")\n",
    "        prompt_index.add(wiki_data_embeddings[prompt_indices])\n",
    "\n",
    "        context = \"\"\n",
    "        \n",
    "        ## Get the top matches\n",
    "        ss, ii = prompt_index.search(question_embeddings, NUM_SENTENCES_INCLUDE)\n",
    "        for _s, _i in zip(ss[prompt_id], ii[prompt_id]):\n",
    "            context += processed_wiki_text_data.loc[prompt_indices]['text'].iloc[_i] + \" \"\n",
    "        \n",
    "    contexts.append(context)"
   ],
   "metadata": {
    "papermill": {
     "duration": 1.609553,
     "end_time": "2023-08-14T10:17:38.836268",
     "exception": false,
     "start_time": "2023-08-14T10:17:37.226715",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:21:25.253020Z",
     "iopub.execute_input": "2023-09-13T07:21:25.253791Z",
     "iopub.status.idle": "2023-09-13T07:21:29.141098Z",
     "shell.execute_reply.started": "2023-09-13T07:21:25.253747Z",
     "shell.execute_reply": "2023-09-13T07:21:29.140113Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b657ae9462b4ef88ef053133e731393"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trn['context'] = contexts"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.024188,
     "end_time": "2023-08-14T10:17:38.878394",
     "exception": false,
     "start_time": "2023-08-14T10:17:38.854206",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:22:17.848361Z",
     "iopub.execute_input": "2023-09-13T07:22:17.848739Z",
     "iopub.status.idle": "2023-09-13T07:22:17.854999Z",
     "shell.execute_reply.started": "2023-09-13T07:22:17.848711Z",
     "shell.execute_reply": "2023-09-13T07:22:17.853640Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trn[[\"prompt\", \"context\", \"A\", \"B\", \"C\", \"D\", \"E\"]].to_csv(\"./test_context.csv\", index=False)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.050945,
     "end_time": "2023-08-14T10:17:38.944423",
     "exception": false,
     "start_time": "2023-08-14T10:17:38.893478",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:22:20.395791Z",
     "iopub.execute_input": "2023-09-13T07:22:20.396193Z",
     "iopub.status.idle": "2023-09-13T07:22:20.455118Z",
     "shell.execute_reply.started": "2023-09-13T07:22:20.396164Z",
     "shell.execute_reply": "2023-09-13T07:22:20.454132Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.015828,
     "end_time": "2023-08-14T10:17:39.007683",
     "exception": false,
     "start_time": "2023-08-14T10:17:38.991855",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv(\"test_context.csv\")\n",
    "test_df.index = list(range(len(test_df)))\n",
    "test_df['id'] = list(range(len(test_df)))\n",
    "test_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:2500]) + \" #### \" +  test_df[\"prompt\"]\n",
    "test_df['answer'] = 'B'"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.037633,
     "end_time": "2023-08-14T10:17:39.605345",
     "exception": false,
     "start_time": "2023-08-14T10:17:39.567712",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:22:49.619701Z",
     "iopub.execute_input": "2023-09-13T07:22:49.620351Z",
     "iopub.status.idle": "2023-09-13T07:22:49.646329Z",
     "shell.execute_reply.started": "2023-09-13T07:22:49.620317Z",
     "shell.execute_reply": "2023-09-13T07:22:49.645369Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_dir = \"/kaggle/input/llm-science-run-context-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ],
   "metadata": {
    "papermill": {
     "duration": 21.360878,
     "end_time": "2023-08-14T10:18:01.027859",
     "exception": false,
     "start_time": "2023-08-14T10:17:39.666981",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:23:33.731829Z",
     "iopub.execute_input": "2023-09-13T07:23:33.732833Z",
     "iopub.status.idle": "2023-09-13T07:23:34.126194Z",
     "shell.execute_reply.started": "2023-09-13T07:23:33.732799Z",
     "shell.execute_reply": "2023-09-13T07:23:34.125120Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\n",
    "options = 'ABCDE'\n",
    "indices = list(range(5))\n",
    "\n",
    "option_to_index = {option: index for option, index in zip(options, indices)}\n",
    "index_to_option = {index: option for option, index in zip(options, indices)}\n",
    "\n",
    "def preprocess(example):\n",
    "    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n",
    "    # so we'll copy our question 5 times before tokenizing\n",
    "    first_sentence = [example['prompt']] * 5\n",
    "    second_sentence = []\n",
    "    for option in options:\n",
    "        second_sentence.append(example[option])\n",
    "    # Our tokenizer will turn our text into token IDs BERT can understand\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n",
    "    tokenized_example['label'] = option_to_index[example['answer']]\n",
    "    return tokenized_example"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.026162,
     "end_time": "2023-08-14T10:18:01.129276",
     "exception": false,
     "start_time": "2023-08-14T10:18:01.103114",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:23:44.492009Z",
     "iopub.execute_input": "2023-09-13T07:23:44.493160Z",
     "iopub.status.idle": "2023-09-13T07:23:44.500568Z",
     "shell.execute_reply.started": "2023-09-13T07:23:44.493114Z",
     "shell.execute_reply": "2023-09-13T07:23:44.499469Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.030447,
     "end_time": "2023-08-14T10:18:01.175589",
     "exception": false,
     "start_time": "2023-08-14T10:18:01.145142",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:23:46.615140Z",
     "iopub.execute_input": "2023-09-13T07:23:46.615508Z",
     "iopub.status.idle": "2023-09-13T07:23:46.626918Z",
     "shell.execute_reply.started": "2023-09-13T07:23:46.615479Z",
     "shell.execute_reply": "2023-09-13T07:23:46.625859Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_test_dataset = Dataset.from_pandas(test_df[['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer']].drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\n",
    "tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"__index_level_0__\"])\n",
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n",
    "test_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, shuffle=False, collate_fn=data_collator)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.493618,
     "end_time": "2023-08-14T10:18:01.685989",
     "exception": false,
     "start_time": "2023-08-14T10:18:01.192371",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:23:49.163142Z",
     "iopub.execute_input": "2023-09-13T07:23:49.163499Z",
     "iopub.status.idle": "2023-09-13T07:23:51.051157Z",
     "shell.execute_reply.started": "2023-09-13T07:23:49.163472Z",
     "shell.execute_reply": "2023-09-13T07:23:51.050261Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Map:   0%|          | 0/200 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f53734406b4541ccbd074b7b43e5afe7"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_ckpts = {\n",
    "    \"/kaggle/input/llm-science-run-context-2\": 0.25,\n",
    "    \"/kaggle/input/how-to-train-open-book-model-part-1/model_v2\": 0.35,\n",
    "    \"/kaggle/input/2023kagglellm-deberta-v3-large-model1\": 0.1,\n",
    "    \"/kaggle/input/my-1-epoch\": 0.1,\n",
    "    \"/kaggle/input/llm-se-debertav3-large\": 0.08,\n",
    "    \"/kaggle/input/science-exam-trained-model-weights/run_0\": 0.06,\n",
    "    \"/kaggle/input/science-exam-trained-model-weights/run_2\": 0.06\n",
    "}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-13T07:24:19.174190Z",
     "iopub.execute_input": "2023-09-13T07:24:19.174582Z",
     "iopub.status.idle": "2023-09-13T07:24:19.180506Z",
     "shell.execute_reply.started": "2023-09-13T07:24:19.174552Z",
     "shell.execute_reply": "2023-09-13T07:24:19.179516Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_ckpts.keys()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-13T07:24:22.204214Z",
     "iopub.execute_input": "2023-09-13T07:24:22.204963Z",
     "iopub.status.idle": "2023-09-13T07:24:22.211816Z",
     "shell.execute_reply.started": "2023-09-13T07:24:22.204927Z",
     "shell.execute_reply": "2023-09-13T07:24:22.210617Z"
    },
    "trusted": true
   },
   "execution_count": 34,
   "outputs": [
    {
     "execution_count": 34,
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['/kaggle/input/llm-science-run-context-2', '/kaggle/input/how-to-train-open-book-model-part-1/model_v2', '/kaggle/input/2023kagglellm-deberta-v3-large-model1', '/kaggle/input/my-1-epoch', '/kaggle/input/llm-se-debertav3-large', '/kaggle/input/science-exam-trained-model-weights/run_0', '/kaggle/input/science-exam-trained-model-weights/run_2'])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "preds = None\n",
    "for ckpt in tqdm(model_ckpts.keys()):\n",
    "    print(ckpt + ':' + str(model_ckpts[ckpt]))\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(ckpt).cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    test_predictions = []\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        test_predictions.append(outputs.logits.cpu().detach())\n",
    "    predictions = torch.cat(test_predictions)\n",
    "    print(predictions.shape)\n",
    "    if preds is not None:\n",
    "        preds += predictions * model_ckpts[ckpt]\n",
    "    else:\n",
    "        preds = predictions * model_ckpts[ckpt]\n",
    "    del model\n",
    "\n",
    "predictions_as_ids = np.argsort(-preds, 1)\n",
    "\n",
    "predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n",
    "# predictions_as_answer_letters[:3]\n",
    "\n",
    "predictions_as_string = test_df['prediction'] = [\n",
    "    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n",
    "]"
   ],
   "metadata": {
    "papermill": {
     "duration": 1.101895,
     "end_time": "2023-08-14T10:18:02.804298",
     "exception": false,
     "start_time": "2023-08-14T10:18:01.702403",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:24:32.463811Z",
     "iopub.execute_input": "2023-09-13T07:24:32.464975Z",
     "iopub.status.idle": "2023-09-13T07:38:42.294331Z",
     "shell.execute_reply.started": "2023-09-13T07:24:32.464930Z",
     "shell.execute_reply": "2023-09-13T07:38:42.293252Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11c3b1ca62a34751a19cd2e924f9c6e9"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "/kaggle/input/llm-science-run-context-2:0.25\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60981eed8c2e4fd8b851b52b41926392"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "torch.Size([200, 5])\n/kaggle/input/how-to-train-open-book-model-part-1/model_v2:0.35\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c5a9d6eff1c41da9193df1ba0a59add"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "torch.Size([200, 5])\n/kaggle/input/2023kagglellm-deberta-v3-large-model1:0.1\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04c17c44d19542b6868958ba60746788"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "torch.Size([200, 5])\n/kaggle/input/my-1-epoch:0.1\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74064ec93af44f65b4d8dee8cb0ce90b"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "torch.Size([200, 5])\n/kaggle/input/llm-se-debertav3-large:0.08\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ab567808ced4fcaacfb0edb013320cd"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "torch.Size([200, 5])\n/kaggle/input/science-exam-trained-model-weights/run_0:0.06\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "396a1f14468f47cda0a69f8b29991709"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "torch.Size([200, 5])\n/kaggle/input/science-exam-trained-model-weights/run_2:0.06\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3e55ecd1dcc4ceb8d7b0eebe224d2c2"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "torch.Size([200, 5])\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "submission = test_df[['id', 'prediction']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.033576,
     "end_time": "2023-08-14T10:19:17.733491",
     "exception": false,
     "start_time": "2023-08-14T10:19:17.699915",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-09-13T07:38:53.604297Z",
     "iopub.execute_input": "2023-09-13T07:38:53.605319Z",
     "iopub.status.idle": "2023-09-13T07:38:53.614319Z",
     "shell.execute_reply.started": "2023-09-13T07:38:53.605256Z",
     "shell.execute_reply": "2023-09-13T07:38:53.613229Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "submission.head(20)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-13T07:38:55.614808Z",
     "iopub.execute_input": "2023-09-13T07:38:55.615261Z",
     "iopub.status.idle": "2023-09-13T07:38:55.631581Z",
     "shell.execute_reply.started": "2023-09-13T07:38:55.615224Z",
     "shell.execute_reply": "2023-09-13T07:38:55.629973Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": [
    {
     "execution_count": 37,
     "output_type": "execute_result",
     "data": {
      "text/plain": "    id prediction\n0    0      D E B\n1    1      A B E\n2    2      A D B\n3    3      C D A\n4    4      D A B\n5    5      B C E\n6    6      A C D\n7    7      D E B\n8    8      C B A\n9    9      A E B\n10  10      E A B\n11  11      A B C\n12  12      C E A\n13  13      E D B\n14  14      B A D\n15  15      B D E\n16  16      E A C\n17  17      D E A\n18  18      A B D\n19  19      E A B",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>D E B</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>A B E</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A D B</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>C D A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>D A B</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>B C E</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>A C D</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>D E B</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>C B A</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>A E B</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>E A B</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>A B C</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>C E A</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>E D B</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>B A D</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>B D E</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>E A C</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>D E A</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>A B D</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>E A B</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  }
 ]
}
