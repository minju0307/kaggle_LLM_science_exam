{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## LLM Science Exam\n\nThis starter notebook walks through a basic example of using BERT to rank the answers to each question. We'll finetune BERT on the 200 public questions, then use the AutoModelForMultipleChoice class to generate probabilities that each option correctly answers the prompt, and finally we'll turn those predictions into a MAP@3-formatted prediction like `A B C`.","metadata":{}},{"cell_type":"code","source":"# Let's import the public training set and take a look\nimport pandas as pd\n\ntrain_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\ntrain_df.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T04:49:58.158682Z","iopub.execute_input":"2023-09-13T04:49:58.159473Z","iopub.status.idle":"2023-09-13T04:49:58.225876Z","shell.execute_reply.started":"2023-09-13T04:49:58.159438Z","shell.execute_reply":"2023-09-13T04:49:58.224837Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"   id                                             prompt  \\\n0   0  Which of the following statements accurately d...   \n1   1  Which of the following is an accurate definiti...   \n2   2  Which of the following statements accurately d...   \n3   3  What is the significance of regularization in ...   \n4   4  Which of the following statements accurately d...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E answer  \n0  MOND is a theory that eliminates the observed ...      D  \n1  Dynamic scaling refers to the evolution of sel...      A  \n2  The triskeles symbol is a representation of th...      A  \n3  Regularizing the mass-energy of an electron wi...      C  \n4  The angular spacing of features in the diffrac...      D  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# For convenience we'll turn our pandas Dataframe into a Dataset\nfrom datasets import Dataset\ntrain_ds = Dataset.from_pandas(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:55:55.139102Z","iopub.execute_input":"2023-09-13T04:55:55.139506Z","iopub.status.idle":"2023-09-13T04:55:56.605317Z","shell.execute_reply.started":"2023-09-13T04:55:55.139476Z","shell.execute_reply":"2023-09-13T04:55:56.604387Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# The path of the model checkpoint we want to use\nmodel_dir = '/kaggle/input/huggingface-bert/bert-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(model_dir)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:56:04.160205Z","iopub.execute_input":"2023-09-13T04:56:04.161103Z","iopub.status.idle":"2023-09-13T04:56:07.063345Z","shell.execute_reply.started":"2023-09-13T04:56:04.161071Z","shell.execute_reply":"2023-09-13T04:56:07.062364Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\noptions = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(example):\n    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n    # so we'll copy our question 5 times before tokenizing\n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    # Our tokenizer will turn our text into token IDs BERT can understand\n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example\n\ntokenized_train_ds = train_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:23:28.039761Z","iopub.execute_input":"2023-09-13T05:23:28.040465Z","iopub.status.idle":"2023-09-13T05:23:28.672182Z","shell.execute_reply.started":"2023-09-13T05:23:28.040432Z","shell.execute_reply":"2023-09-13T05:23:28.671287Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0499eea8c090446187c856aa3e6f9124"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Following datacollator (adapted from https://huggingface.co/docs/transformers/tasks/multiple_choice)\n# will dynamically pad our questions at batch-time so we don't have to make every question the length\n# of our longest question.\nfrom dataclasses import dataclass\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom typing import Optional, Union\nimport torch\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:24:22.281068Z","iopub.execute_input":"2023-09-13T05:24:22.281458Z","iopub.status.idle":"2023-09-13T05:24:27.834341Z","shell.execute_reply.started":"2023-09-13T05:24:22.281428Z","shell.execute_reply":"2023-09-13T05:24:27.833347Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Now we'll instatiate the model that we'll finetune on our public dataset, then use to\n# make prediction on the private dataset.\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:24:27.836397Z","iopub.execute_input":"2023-09-13T05:24:27.837139Z","iopub.status.idle":"2023-09-13T05:24:49.264867Z","shell.execute_reply.started":"2023-09-13T05:24:27.837103Z","shell.execute_reply":"2023-09-13T05:24:49.263755Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nSome weights of the model checkpoint at /kaggle/input/huggingface-bert/bert-base-cased were not used when initializing BertForMultipleChoice: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/huggingface-bert/bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# The arguments here are selected to run quickly; feel free to play with them.\nmodel_dir = 'finetuned_bert'\ntraining_args = TrainingArguments(\n    output_dir=model_dir,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    learning_rate=5e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    report_to='none'\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:25:21.038641Z","iopub.execute_input":"2023-09-13T05:25:21.039002Z","iopub.status.idle":"2023-09-13T05:25:21.136784Z","shell.execute_reply.started":"2023-09-13T05:25:21.038974Z","shell.execute_reply":"2023-09-13T05:25:21.135692Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Generally it's a bad idea to validate on your training set, but because our training set\n# for this problem is so small we're going to train on all our data.\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_ds,\n    eval_dataset=tokenized_train_ds,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:25:23.519664Z","iopub.execute_input":"2023-09-13T05:25:23.520014Z","iopub.status.idle":"2023-09-13T05:25:31.467487Z","shell.execute_reply.started":"2023-09-13T05:25:23.519986Z","shell.execute_reply":"2023-09-13T05:25:31.466407Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Training should take about a minute\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:25:41.367555Z","iopub.execute_input":"2023-09-13T05:25:41.367912Z","iopub.status.idle":"2023-09-13T05:26:40.068465Z","shell.execute_reply.started":"2023-09-13T05:25:41.367884Z","shell.execute_reply":"2023-09-13T05:26:40.067234Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [75/75 00:50, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.560723</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.574030</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.535435</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=75, training_loss=1.5942584228515626, metrics={'train_runtime': 58.3413, 'train_samples_per_second': 10.284, 'train_steps_per_second': 1.286, 'total_flos': 156631893796800.0, 'train_loss': 1.5942584228515626, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Now we can actually make predictions on our questions\npredictions = trainer.predict(tokenized_train_ds)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:26:40.072643Z","iopub.execute_input":"2023-09-13T05:26:40.074027Z","iopub.status.idle":"2023-09-13T05:26:44.207534Z","shell.execute_reply.started":"2023-09-13T05:26:40.073982Z","shell.execute_reply":"2023-09-13T05:26:44.206294Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"# The following function gets the indices of the highest scoring answers for each row\n# and converts them back to our answer format (A, B, C, D, E)\nimport numpy as np\ndef predictions_to_map_output(predictions):\n    sorted_answer_indices = np.argsort(-predictions)\n    top_answer_indices = sorted_answer_indices[:,:3] # Get the first three answers in each row\n    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:26:44.209416Z","iopub.execute_input":"2023-09-13T05:26:44.210139Z","iopub.status.idle":"2023-09-13T05:26:44.216579Z","shell.execute_reply.started":"2023-09-13T05:26:44.210105Z","shell.execute_reply":"2023-09-13T05:26:44.215644Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Let's double check our output looks correct:\npredictions_to_map_output(predictions.predictions)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:27:17.148523Z","iopub.execute_input":"2023-09-13T05:27:17.148924Z","iopub.status.idle":"2023-09-13T05:27:17.169951Z","shell.execute_reply.started":"2023-09-13T05:27:17.148894Z","shell.execute_reply":"2023-09-13T05:27:17.168387Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array(['B D A', 'D B A', 'A D C', 'A E D', 'E A D', 'B E A', 'C D B',\n       'B E D', 'E C B', 'A E C', 'C B E', 'D A E', 'C B E', 'E A D',\n       'A C E', 'B A C', 'B E A', 'E B A', 'A D C', 'E D A', 'D B C',\n       'D C E', 'C A E', 'C A B', 'E A D', 'E D A', 'A D E', 'D B A',\n       'E B C', 'C B E', 'E B C', 'E C A', 'E D B', 'D E B', 'E C B',\n       'D E A', 'B E A', 'A D E', 'E D A', 'E A C', 'B E D', 'B C A',\n       'B A C', 'D C B', 'D E C', 'B A E', 'B C A', 'C B A', 'B E C',\n       'B A D', 'B D C', 'E D B', 'C A D', 'A C D', 'B A C', 'A D C',\n       'C D A', 'C B A', 'E C B', 'E B D', 'B E D', 'E C B', 'D A C',\n       'B A C', 'D A E', 'A B E', 'C D E', 'E D B', 'E C D', 'D E A',\n       'B D E', 'A C E', 'D E A', 'B D A', 'D B C', 'C B E', 'A B C',\n       'B A E', 'C D E', 'B D A', 'D C E', 'A E C', 'C E D', 'B A C',\n       'C B A', 'B C E', 'A B E', 'B D A', 'E A C', 'D A B', 'D B E',\n       'B D C', 'E C B', 'E B D', 'E A B', 'C B E', 'C D A', 'B D C',\n       'E B D', 'E D C', 'A B D', 'B C A', 'A C D', 'E B C', 'E D B',\n       'D B C', 'A B C', 'D E B', 'E C A', 'D E C', 'A E C', 'D B C',\n       'A B E', 'B D E', 'D A C', 'E B C', 'C D B', 'C E D', 'D A B',\n       'B A C', 'D A C', 'C B A', 'B E C', 'B A D', 'E B D', 'D E C',\n       'D B C', 'C E B', 'E B D', 'D E B', 'D C B', 'E D C', 'E D B',\n       'B C D', 'A C E', 'E B D', 'E B D', 'D E A', 'A C B', 'A D C',\n       'C B E', 'E D C', 'E D C', 'D A C', 'C E B', 'B C E', 'C E A',\n       'C A D', 'B D A', 'B D A', 'E D B', 'B D A', 'E A C', 'A D C',\n       'A C B', 'B D E', 'B D E', 'A C D', 'A D E', 'C A E', 'A D B',\n       'C E D', 'A D C', 'B D E', 'E B D', 'D C A', 'C D A', 'D B E',\n       'E B A', 'A C B', 'B C E', 'E B C', 'A E B', 'C B D', 'E A B',\n       'E C D', 'A E B', 'D C B', 'D C A', 'C B D', 'C A B', 'C E B',\n       'A E C', 'C E D', 'A E C', 'A E D', 'C D E', 'E D A', 'C D B',\n       'C B E', 'D E B', 'C D B', 'B A E', 'C B A', 'B A D', 'C D E',\n       'B C E', 'E B A', 'C B D', 'A B E'], dtype='<U5')"},"metadata":{}}]},{"cell_type":"code","source":"# Now we can load up our test set to use our model on!\n# The public test.csv isn't the real dataset (it's actually just a copy of train.csv without the answer column)\n# but it has the same format as the real test set, so using it is a good way to ensure our code will work when we submit.\ntest_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:27:55.740721Z","iopub.execute_input":"2023-09-13T05:27:55.741078Z","iopub.status.idle":"2023-09-13T05:27:55.770230Z","shell.execute_reply.started":"2023-09-13T05:27:55.741052Z","shell.execute_reply":"2023-09-13T05:27:55.769374Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   id                                             prompt  \\\n0   0  Which of the following statements accurately d...   \n1   1  Which of the following is an accurate definiti...   \n2   2  Which of the following statements accurately d...   \n3   3  What is the significance of regularization in ...   \n4   4  Which of the following statements accurately d...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E  \n0  MOND is a theory that eliminates the observed ...  \n1  Dynamic scaling refers to the evolution of sel...  \n2  The triskeles symbol is a representation of th...  \n3  Regularizing the mass-energy of an electron wi...  \n4  The angular spacing of features in the diffrac...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# There are more verbose/elegant ways of doing this, but if we give our test set a random `answer` column\n# we can make predictions directly with our trainer.\ntest_df['answer'] = 'A'\n\n# Other than that we'll preprocess it in the same way we preprocessed test.csv\ntest_ds = Dataset.from_pandas(test_df)\ntokenized_test_ds = test_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:27:58.968994Z","iopub.execute_input":"2023-09-13T05:27:58.969378Z","iopub.status.idle":"2023-09-13T05:27:59.298303Z","shell.execute_reply.started":"2023-09-13T05:27:58.969340Z","shell.execute_reply":"2023-09-13T05:27:59.297451Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd9e7f2bc19241219151b0f377d97226"}},"metadata":{}}]},{"cell_type":"code","source":"# Here we'll generate our \"real\" predictions on the test set\ntest_predictions = trainer.predict(tokenized_test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:28:08.067961Z","iopub.execute_input":"2023-09-13T05:28:08.068311Z","iopub.status.idle":"2023-09-13T05:28:11.972228Z","shell.execute_reply.started":"2023-09-13T05:28:08.068282Z","shell.execute_reply":"2023-09-13T05:28:11.971239Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"# Now we can create our submission using the id column from test.csv\nsubmission_df = test_df[['id']]\nsubmission_df['prediction'] = predictions_to_map_output(test_predictions.predictions)\n\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:28:32.808156Z","iopub.execute_input":"2023-09-13T05:28:32.808532Z","iopub.status.idle":"2023-09-13T05:28:32.838344Z","shell.execute_reply.started":"2023-09-13T05:28:32.808501Z","shell.execute_reply":"2023-09-13T05:28:32.837119Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/1317637749.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  submission_df['prediction'] = predictions_to_map_output(test_predictions.predictions)\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   id prediction\n0   0      B D A\n1   1      D B A\n2   2      A D C\n3   3      A E D\n4   4      E A D","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>B D A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>D B A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>A D C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>A E D</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>E A D</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Once we write our submission file we're good to submit!\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T05:28:37.453398Z","iopub.execute_input":"2023-09-13T05:28:37.453782Z","iopub.status.idle":"2023-09-13T05:28:37.464503Z","shell.execute_reply.started":"2023-09-13T05:28:37.453741Z","shell.execute_reply":"2023-09-13T05:28:37.463534Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}