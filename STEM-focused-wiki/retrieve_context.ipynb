{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fdd2759-e732-4911-8895-1970abb3db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import ctypes\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For RAG\n",
    "import faiss\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk, Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# For LLM\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "from accelerate import init_empty_weights\n",
    "from accelerate.utils.modeling import set_module_tensor_to_device\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c971a08-ffad-44dd-894f-dfa11fc2f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_SentenceTransformer:\n",
    "    def __init__(self, checkpoint, device=\"cuda:0\"):\n",
    "        self.device = device\n",
    "        self.checkpoint = checkpoint\n",
    "        self.model = AutoModel.from_pretrained(checkpoint).to(self.device).half()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    def transform(self, batch):\n",
    "        tokens = self.tokenizer(batch[\"text\"], truncation=True, padding=True, return_tensors=\"pt\", max_length=MAX_SEQ_LEN)\n",
    "        return tokens.to(self.device)  \n",
    "\n",
    "    def get_dataloader(self, sentences, batch_size=32):\n",
    "        sentences = [\"Represent this sentence for searching relevant passages: \" + x for x in sentences]\n",
    "        dataset = Dataset.from_dict({\"text\": sentences})\n",
    "        dataset.set_transform(self.transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        return dataloader\n",
    "\n",
    "    def encode(self, sentences, show_progress_bar=False, batch_size=32):\n",
    "        dataloader = self.get_dataloader(sentences, batch_size=batch_size)\n",
    "        pbar = tqdm(dataloader) if show_progress_bar else dataloader\n",
    "\n",
    "        embeddings = []\n",
    "        for batch in pbar:\n",
    "            with torch.no_grad():\n",
    "                e = self.model(**batch).pooler_output\n",
    "                e = F.normalize(e, p=2, dim=1)\n",
    "                embeddings.append(e.detach().cpu().numpy())\n",
    "        embeddings = np.concatenate(embeddings, axis=0)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f64194d7-68ce-4ad3-b61d-df79b8e2295b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MMLU_train_set.csv',\n",
       " 'MMLU_science_set.csv',\n",
       " 'MMLU_physics_set.csv',\n",
       " 'MMLU_dev_set.csv',\n",
       " 'MMLU_sampling_train_set.csv']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "files=[i for i in os.listdir('../mmlu-dataset') if re.findall('csv', i)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ab20d27-a9c4-4331-8c27-b6884501654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt embedding, t=0.0s\n",
      "Loading faiss index, t=45.3s\n",
      "Starting text search, t=49.7s\n",
      "Starting context extraction, t=50.4s\n"
     ]
    }
   ],
   "source": [
    "## bge-small-faiss embedding \n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(f\"../mmlu-dataset/{files[4]}\")\n",
    "df['A']=df['A'].apply(str)\n",
    "df['B']=df['B'].apply(str)\n",
    "df['C']=df['C'].apply(str)\n",
    "df['D']=df['D'].apply(str)\n",
    "# df['E']=df['E'].apply(str) ## sienceexam\n",
    "\n",
    "NUM_TITLES = 5\n",
    "MAX_SEQ_LEN = 512\n",
    "MODEL_PATH = \"output/bge-small-faiss/\"\n",
    "\n",
    "## load embedding model\n",
    "start = time()\n",
    "print(f\"Starting prompt embedding, t={time() - start :.1f}s\")\n",
    "model = my_SentenceTransformer(MODEL_PATH, device=\"cuda:2\") ## 직접 정의한 sentencetransformer 사용\n",
    "\n",
    "## Get query embedding\n",
    "# f = lambda row : \" \".join([row[\"prompt\"], row[\"A\"], row[\"B\"], row[\"C\"], row[\"D\"], row[\"E\"]]) ## scienceexam\n",
    "f = lambda row : \" \".join([row[\"question\"], row[\"A\"], row[\"B\"], row[\"C\"], row[\"D\"]]) ## MMLU\n",
    "inputs = df.apply(f, axis=1).values # better results than prompt only\n",
    "prompt_embeddings = model.encode(inputs, show_progress_bar=False)\n",
    "\n",
    "## faiss wikipedia index 불러오기\n",
    "print(f\"Loading faiss index, t={time() - start :.1f}s\")\n",
    "faiss_index = faiss.read_index(MODEL_PATH + '/faiss.index')\n",
    "faiss_index = faiss.index_cpu_to_all_gpus(faiss_index) # OOM이 일어날 때는 지우기 \n",
    "\n",
    "## top-5의 관련있는 인덱스 가져오기 \n",
    "print(f\"Starting text search, t={time() - start :.1f}s\")\n",
    "search_index = faiss_index.search(np.float32(prompt_embeddings), NUM_TITLES)[1]\n",
    "\n",
    "## 인덱스를 찾아서 실제 문서 가져오기 \n",
    "print(f\"Starting context extraction, t={time() - start :.1f}s\")\n",
    "dataset = load_from_disk(\"dataset/all-paraphs-parsed-expanded\")\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, \"context\"] = \"-\" + \"\\n-\".join([dataset[int(j)][\"text\"] for j in search_index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4f0f7-a466-4b2b-bb13-8f10e2401ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32fce759-52ef-41ad-a27b-132b90634778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHANGSHA,Feb.14(Xinhua)----Areas of China affe...</td>\n",
       "      <td>one week</td>\n",
       "      <td>two weeks</td>\n",
       "      <td>one month</td>\n",
       "      <td>two months</td>\n",
       "      <td>C</td>\n",
       "      <td>-The provinces of Hubei, Henan, Shandong, Jian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1English people have three meals  a day. They ...</td>\n",
       "      <td>cakes, fruit or ice cream</td>\n",
       "      <td>hamburgers or sandwiches</td>\n",
       "      <td>soup and rice</td>\n",
       "      <td>some porridge, eggs and meat</td>\n",
       "      <td>D</td>\n",
       "      <td>-People usually have two or three meals a day....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XI'AN---Seven people died in a fire early on W...</td>\n",
       "      <td>The news report didn't mention the loss caused...</td>\n",
       "      <td>After reading the report we know how the fire ...</td>\n",
       "      <td>The reporter tended to think the bomb had some...</td>\n",
       "      <td>The police refused to admit the bomb had anyth...</td>\n",
       "      <td>C</td>\n",
       "      <td>-Ronan Point was a 23-story council tower bloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter is dangerous because it's so difficult ...</td>\n",
       "      <td>Traffic accidents take place easily in winter.</td>\n",
       "      <td>Fog and melting snow often cause car accidents.</td>\n",
       "      <td>The stopping distance on ice is as long as the...</td>\n",
       "      <td>In winter you should drive your car with great...</td>\n",
       "      <td>C</td>\n",
       "      <td>-Land travel Ice forming on roads is a dangero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Telepathy: Mind-to-mind Contact Telepathy is t...</td>\n",
       "      <td>Help them have a strong desire to communicate.</td>\n",
       "      <td>Separate them all the time.</td>\n",
       "      <td>Help them link up their unconscious minds.</td>\n",
       "      <td>Let them spend much time together.</td>\n",
       "      <td>B</td>\n",
       "      <td>-Telepathy (from Ancient Greek τῆλε (têle) 'di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  CHANGSHA,Feb.14(Xinhua)----Areas of China affe...   \n",
       "1  1English people have three meals  a day. They ...   \n",
       "2  XI'AN---Seven people died in a fire early on W...   \n",
       "3  Winter is dangerous because it's so difficult ...   \n",
       "4  Telepathy: Mind-to-mind Contact Telepathy is t...   \n",
       "\n",
       "                                                   A  \\\n",
       "0                                           one week   \n",
       "1                          cakes, fruit or ice cream   \n",
       "2  The news report didn't mention the loss caused...   \n",
       "3     Traffic accidents take place easily in winter.   \n",
       "4     Help them have a strong desire to communicate.   \n",
       "\n",
       "                                                   B  \\\n",
       "0                                          two weeks   \n",
       "1                           hamburgers or sandwiches   \n",
       "2  After reading the report we know how the fire ...   \n",
       "3    Fog and melting snow often cause car accidents.   \n",
       "4                        Separate them all the time.   \n",
       "\n",
       "                                                   C  \\\n",
       "0                                          one month   \n",
       "1                                      soup and rice   \n",
       "2  The reporter tended to think the bomb had some...   \n",
       "3  The stopping distance on ice is as long as the...   \n",
       "4         Help them link up their unconscious minds.   \n",
       "\n",
       "                                                   D answer  \\\n",
       "0                                         two months      C   \n",
       "1                       some porridge, eggs and meat      D   \n",
       "2  The police refused to admit the bomb had anyth...      C   \n",
       "3  In winter you should drive your car with great...      C   \n",
       "4                 Let them spend much time together.      B   \n",
       "\n",
       "                                             context  \n",
       "0  -The provinces of Hubei, Henan, Shandong, Jian...  \n",
       "1  -People usually have two or three meals a day....  \n",
       "2  -Ronan Point was a 23-story council tower bloc...  \n",
       "3  -Land travel Ice forming on roads is a dangero...  \n",
       "4  -Telepathy (from Ancient Greek τῆλε (têle) 'di...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f0beee2d-d4c4-49dc-98bb-81f02e43efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"../mmlu-dataset/{files[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2397dfe-7dc7-45ca-9db8-8e146f093106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 뽑힌 context의 내용 확인하기 \n",
    "\n",
    "context=df['context'].tolist()\n",
    "\n",
    "for idx,q in enumerate(df['prompt'].tolist()):\n",
    "    print (q)\n",
    "    print(context[idx])\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ec644c1-74bb-40a2-8b3e-70f4e3e7723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2374, 1301, 3455, 4670, 10452, 4127, 4777, 7681, 3167, 2940, 2488, 6425, 3673, 3493, 10356, 3375, 2482, 2916, 4378, 3397, 3673, 6444, 4134, 2942, 4719, 3193, 6614, 4204, 2803, 3773, 3237, 2787, 3039, 3270, 2974, 2847, 2892, 4385, 4191, 3060, 2683, 5736, 2526, 5083, 4654, 5091, 5980, 5918, 4403, 3716, 3488, 3292, 3559, 2375, 3419, 549, 634, 4314, 4079, 5660, 4543, 5049, 6895, 1420, 9507, 3025, 2707, 3025, 2994, 2922, 2324, 2324, 7101, 6268, 3068, 3163, 4301, 2435, 3377, 2676, 5560, 5724, 7228, 6120, 3149, 3019, 2997, 2061, 2988, 3119, 6337, 8559, 12943, 3177, 4661, 4153, 3169, 3384, 3210, 3354, 2778, 3129, 4629, 5263, 4091, 3027, 1982, 3952, 3685, 4206, 4510, 4539, 6632, 3854, 4938, 5167, 3176, 5510, 2559, 5564, 3302, 4537, 2693, 5864, 10407, 3162, 2159, 3021, 2692, 3952, 5576, 5011, 3413, 3689, 4776, 2547, 5453, 2396, 2383, 3173, 2786, 4966, 4394, 3780, 4801, 2754, 1383, 4452, 4014, 5787, 7748, 1839, 5194, 9359, 6065, 2645, 3047, 5707, 4428, 5802, 2693, 4376, 3300, 2967, 3163, 2841, 7796, 4090, 4034, 7550, 3716, 6290, 4334, 5205, 2882, 4381, 1611, 1855, 2210, 5223, 3880, 3180, 5218, 3462, 2883, 4684, 2790, 3770, 4354, 4026, 5086, 3931, 7401, 3255, 4462, 5070, 3920, 2815, 5376, 4908, 2991, 2075, 3653, 3601, 5479, 2614, 10264, 3271, 3154, 8452, 2981, 2878, 3737, 2707, 3784, 4548, 3700, 4339, 9349, 2903, 4269, 3183, 2607, 5161, 3751, 3156, 5318, 4515, 3408, 4309, 3734, 3485, 3481, 9665, 3183, 3491, 5075, 3200, 4894, 4009, 2589, 5170, 3747, 3224, 2574, 2896, 3253, 5128, 3149, 4329, 4114, 3607, 2680, 2796, 3835, 1460, 3300, 1403, 2137, 3008, 4044, 2409, 3733, 2442, 5352, 3841, 4489, 4563, 2492, 4774, 4456, 3671, 5040, 6388, 4499, 5959, 3255, 4459, 2344, 4657, 4978, 3143, 4729, 7602, 5167, 3929, 4115, 7512, 5993, 3028, 2987, 4086, 4593, 3462, 3142, 3144, 5139, 4017, 5909, 4650, 2524, 1777, 4146, 2064, 1963, 2739, 2965, 2222, 3880, 2288, 2678, 2859, 3164, 6302, 9956, 3171, 4160, 2767, 2954, 4397, 2774, 3164, 3318, 3842, 2985, 12198, 4095, 1891, 4528, 749, 2110, 2980, 2728, 3848, 3499, 4330, 3399, 5631, 4438, 3363, 3310, 3367, 5709, 3124, 1362, 2654, 3429, 2256, 2821, 3147, 5137, 2399, 2296, 2200, 3369, 3898, 3040, 3599, 4047, 4167, 3117, 4253, 3161, 3313, 3604, 3847, 3649, 3102, 5028, 4137, 4169, 2900, 5588, 5499, 5788, 2212, 3829, 7757, 2083, 4631, 2700, 2534, 2766, 2885, 4561, 3681, 5182, 5205, 3407, 2600, 3453, 5839, 3147, 4091, 5457, 6519, 7889, 3617, 4446, 7291, 10003, 12117, 11691, 19236, 10746, 2178, 3264, 3192, 2839, 3267, 4844, 4538, 2973, 5087, 6028, 5391, 3426, 3471, 3780, 2997, 2588, 4716, 2965, 2523, 4223, 2045, 2726, 2856, 2487, 3839, 1531, 2069, 2455, 4485, 8927, 2382, 1548, 2022, 2971, 3598, 3669, 3844, 3534, 3722, 4709, 2638, 2896, 2681, 2528, 3096, 3441, 3565, 2173, 4942, 7618, 2696, 2859, 3043, 2876, 2833, 9381, 5040, 2492, 3848, 2796, 3632, 2691, 2017, 2658, 2651, 3157, 4455, 3328, 4247, 3038, 4815, 7260, 2864, 5531, 6390, 2786, 2759, 2851, 3228, 3404, 3212, 4514, 5899, 4313, 3700, 4847, 4847, 4847, 7191, 4847, 5207, 4256, 4744, 2596, 3749, 2205, 3666, 3041, 3321, 4391, 4273, 5049, 5157, 9505, 5132, 1862, 2098, 2503, 3272, 4401, 6397, 5635, 6947, 4501, 5003, 2146, 4136, 4365, 5002, 1354, 2362, 2609, 2706, 2609, 2848, 3253, 3934, 3455, 7243, 1687, 3136, 5590, 6983, 3613, 3848, 2430, 6032, 7173, 7104, 3328, 2556, 5248, 6214, 3080, 4934, 4533, 2724, 3326, 4054, 6608, 1976, 2715, 2506, 2318, 2220, 2046, 2528, 4422, 5319, 6199, 1895, 2936, 4154, 1526, 2989, 2513, 2475, 2868, 2908, 4097, 1905, 4263, 3170, 4158, 6007, 4208, 6913, 7610, 5437, 7332, 2205, 3448, 2155, 2026, 2173, 3672, 3573, 3450, 3507, 3426, 2944, 1717, 3684, 1453, 2111, 4700, 3787, 2363, 4994, 4155, 2733, 3823, 3097, 3043, 2760, 4821, 3436, 3108, 1849, 3213, 3256, 3035, 1937, 2324, 4752, 3092, 3400, 2468, 5774, 2821, 1901, 3395, 1955, 8130, 2931, 4426, 4022, 6340, 4493, 5654, 2557, 3243, 1899, 2789, 2662, 1566, 3069, 1837, 5522, 2685, 2863, 2020, 3601, 3911, 3259, 6291, 3049, 2463, 3323, 2705, 3989, 2572, 7205, 3563, 3379, 4793, 2330, 3104, 2463, 5248, 1687, 3315, 4694, 2877, 2501, 4016, 3232, 3525, 5188, 5250, 3032, 4924, 3922, 3922, 3908, 2186, 5420, 3651, 4262, 2583, 3027, 4377, 3519, 4894, 4045, 3193, 2658, 1987, 2899, 3404, 2444, 4345, 2881, 6874, 4496, 4454, 6307, 5194, 7732, 4498, 2793, 4019, 7238, 3116, 2991, 6371, 4963, 6579, 5408, 6528, 3748, 5356, 4082, 8293, 3678, 3267, 4523, 2827, 5766, 3400, 3480, 4320, 5260, 2859, 3786, 3564, 5600, 3154, 3610, 1939, 3410, 5023, 4632, 3483, 5262, 3083, 5867, 6665, 3316, 5434, 4339, 3302, 3718, 3894, 3460, 5683, 5594, 6418, 8067, 4369, 2365, 3388, 3292, 3651, 4485, 3043, 3711, 3913, 3654, 3136, 2864, 3669, 4607, 4268, 2564, 4219, 4971, 3753, 2796, 4544, 3433, 2862, 3128, 3189, 3239, 2464, 1477, 1298, 7706, 4660, 5156, 4604, 5141, 4442, 5460, 2054, 8030, 7508, 4044, 4630, 2645, 4871, 4423, 2111, 2346, 3338, 4593, 2952, 3928, 3186, 1513, 2519, 3078, 5315, 3968, 3228, 4233, 2554, 3540, 3501, 2188, 4652, 3867, 3942, 3717, 2642, 4998, 3244, 2863, 4419, 3371, 4240, 3894, 3697, 2878, 2279, 1766, 1840, 4056, 3952, 1921, 2561, 2778, 2958, 3020, 3032, 2145, 3255, 2671, 2367, 5016, 6166, 5129, 7093, 3365, 2345, 3347, 3689, 7062, 4827, 3139, 3343, 1707, 4286, 2243, 4964, 3771, 3217, 3342, 3342, 2778, 2551, 2435, 4542, 5572, 4560, 3557, 2600, 3813, 3557, 2516, 2558, 3045, 2858, 3165, 7456, 4871, 4817, 3567, 2984, 4062, 3393, 4321, 3966, 6545, 2558, 2815, 2547, 2815, 2815, 2665, 3421, 3018, 3699, 2763, 6574, 2827, 2374, 3299, 2789, 5703, 5234, 8141, 8295, 3500, 3520, 2390, 3936, 2742, 3743, 3154, 8065, 2636, 7328, 6613, 3511, 2740, 2184, 3302, 6526, 6005, 5759, 6684, 5149, 6105, 5002, 3734, 2324, 3904, 3536, 3117, 3280, 3505, 3048, 3460, 3032, 3118, 3471, 2604, 4099, 2321, 2793, 3389, 5625, 3015, 2929, 3162, 3352, 2784, 3345, 3576, 1533, 2196, 4093, 4591, 2973, 3305, 4997, 2239, 4825, 4410, 3449, 3904, 2754, 3212, 2660, 3287, 1712, 2903, 4251, 5861, 3425, 5257, 7743, 8961, 3904, 2650, 2385, 2048, 3904, 4868, 8241, 3034, 3025, 3985, 3802, 4021, 3512, 5205, 3493, 4553, 5741, 5708, 5951, 6696]\n",
      "19872.155\n"
     ]
    }
   ],
   "source": [
    "## context의 길이 알아보기 \n",
    "\n",
    "lengths=[]\n",
    "for c in context:\n",
    "    lengths.append(len(c))\n",
    "\n",
    "hap=0\n",
    "for l in lengths:\n",
    "    hap+=l\n",
    "\n",
    "print(lengths)\n",
    "print(hap/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830cd34-ea27-4634-b396-f2a0f5933e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
